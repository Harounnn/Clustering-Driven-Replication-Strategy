version: "3.8"

services:
  namenode:
      build:
        context: .
        dockerfile: namenode.Dockerfile
      image: local/hadoop-namenode:py3
      container_name: namenode
      ports:
        - "9870:9870"
        - "9000:9000"
      volumes:
        - namenode:/hadoop/dfs/name
        - ../src:/opt/synth-code:cached
      env_file:
        - ./hadoop.env
      environment:
        - CLUSTER_NAME=localcluster
      restart: unless-stopped

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    depends_on:
      - namenode
    volumes:
      - datanode:/hadoop/dfs/data
      - ../src:/opt/synth-code:cached
    env_file:
      - ./hadoop.env
    restart: unless-stopped

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    depends_on:
      - namenode
    ports:
      - "8088:8088"   # YARN ResourceManager UI
    env_file:
      - ./hadoop.env
    restart: unless-stopped

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    depends_on:
      - resourcemanager
      - datanode
    env_file:
      - ./hadoop.env
    restart: unless-stopped

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    depends_on:
      - namenode
    ports:
      - "19888:19888"   
    env_file:
      - ./hadoop.env
    restart: unless-stopped

  spark:
    image: apache/spark:3.5.2
    container_name: spark
    env_file:
      - ./hadoop.env
    volumes:
      - ../src:/opt/synth-code:cached
      - ./hadoop_conf:/opt/hadoop-conf:cached
    working_dir: /opt/synth-code
    entrypoint: ["/bin/bash","-c","tail -f /dev/null"]
    depends_on:
      - namenode
      - resourcemanager
    restart: unless-stopped


volumes:
  namenode:
  datanode:
